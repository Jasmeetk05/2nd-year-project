{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/u6GK5DKBNmSq/q7s6oCH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jasmeetk05/2nd-year-project/blob/main/Copy_of_Untitled59.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4jv2xUK9LxV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch sentencepiece scikit-learn numpy tqdm flask\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4wGSDAU9PaW",
        "outputId": "e37f613f-3502-41cb-f092-f8d895215614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken \"323g1mtR9moA9F2y4FClQhTI2dz_5PtgpJqGKJ5nthEf5qKf6\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsnpDXoLKXIY",
        "outputId": "a4a8a9c6-52a2-4b53-af3e-8470c214e957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For our app interface\n",
        "Step 1. Install dependencies"
      ],
      "metadata": {
        "id": "Jq29ZviqM4PD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1 â€” install dependencies (run first)\n",
        "!pip install -q streamlit pyngrok bcrypt transformers torch sentencepiece scikit-learn fpdf textstat spacy textblob matplotlib nltk\n",
        "# Optional: if you want language_tool (Java) uncomment below (not required)\n",
        "# !pip install -q language_tool_python\n",
        "\n",
        "# Download spaCy and NLTK models\n",
        "!python -m spacy download en_core_web_sm >/dev/null 2>&1 || true\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "print(\"âœ… Install step finished.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThplC7M8Igbp",
        "outputId": "0582685f-2cac-4041-c82e-589e82be8eb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Install step finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ§  Cell 1 â€” setup dependencies and corpora\n",
        "!pip install textblob language_tool_python pyngrok streamlit reportlab\n",
        "!python -m textblob.download_corpora\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esVXAQZ8MkLK",
        "outputId": "3fa6fdec-3886-4046-8dfc-bda7aec17d5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.12/dist-packages (0.19.0)\n",
            "Collecting language_tool_python\n",
            "  Downloading language_tool_python-2.9.4-py3-none-any.whl.metadata (55 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.4.0)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.50.0)\n",
            "Collecting reportlab\n",
            "  Downloading reportlab-4.4.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.12/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from language_tool_python) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from language_tool_python) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from language_tool_python) (5.9.5)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.12/dist-packages (from language_tool_python) (0.10.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from reportlab) (3.4.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.7.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->language_tool_python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->language_tool_python) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->language_tool_python) (2025.10.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading language_tool_python-2.9.4-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.6/55.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading reportlab-4.4.4-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: reportlab, language_tool_python\n",
            "Successfully installed language_tool_python-2.9.4 reportlab-4.4.4\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Create app Structure"
      ],
      "metadata": {
        "id": "sQQI2HS4aEXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2 â€” write app.py (run this second)\n",
        "app_code = \"\"\"\n",
        "import streamlit as st\n",
        "import sqlite3, bcrypt, random, time\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from fpdf import FPDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import textstat\n",
        "import spacy\n",
        "from transformers import pipeline\n",
        "from textblob import TextBlob\n",
        "import difflib\n",
        "import os\n",
        "\n",
        "# ---------- CONFIG ----------\n",
        "DB = \"users.db\"\n",
        "FEEDBACK_MODEL = \"google/flan-t5-small\"   # instruction-following small model for feedback & rewriting\n",
        "DEVICE = 0 if __import__('torch').cuda.is_available() else -1\n",
        "\n",
        "# ---------- DATABASE ----------\n",
        "conn = sqlite3.connect(DB, check_same_thread=False)\n",
        "c = conn.cursor()\n",
        "c.execute('''CREATE TABLE IF NOT EXISTS users (\n",
        "    email TEXT PRIMARY KEY,\n",
        "    password BLOB NOT NULL\n",
        ")''')\n",
        "c.execute('''CREATE TABLE IF NOT EXISTS history (\n",
        "    email TEXT,\n",
        "    essay TEXT,\n",
        "    score REAL,\n",
        "    feedback TEXT,\n",
        "    grammar_score REAL,\n",
        "    coherence_score REAL,\n",
        "    plagiarism_score REAL,\n",
        "    date TEXT\n",
        ")''')\n",
        "conn.commit()\n",
        "\n",
        "# Auto-migration (add missing columns if schema older)\n",
        "existing = [row[1] for row in c.execute(\"PRAGMA table_info(history)\").fetchall()]\n",
        "for col, ctype in [(\"feedback\",\"TEXT\"), (\"grammar_score\",\"REAL\"), (\"coherence_score\",\"REAL\"), (\"plagiarism_score\",\"REAL\")]:\n",
        "    if col not in existing:\n",
        "        try:\n",
        "            c.execute(f\"ALTER TABLE history ADD COLUMN {col} {ctype}\")\n",
        "            conn.commit()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "# ---------- Session state init ----------\n",
        "if \"logged_in\" not in st.session_state:\n",
        "    st.session_state[\"logged_in\"] = False\n",
        "    st.session_state[\"user_email\"] = None\n",
        "if \"otp_storage\" not in st.session_state:\n",
        "    st.session_state[\"otp_storage\"] = {}\n",
        "if \"feedback_model\" not in st.session_state:\n",
        "    st.session_state[\"feedback_model\"] = None\n",
        "if \"rewriter\" not in st.session_state:\n",
        "    st.session_state[\"rewriter\"] = None\n",
        "if \"spacy_nlp\" not in st.session_state:\n",
        "    try:\n",
        "        st.session_state[\"spacy_nlp\"] = spacy.load(\"en_core_web_sm\")\n",
        "    except:\n",
        "        st.session_state[\"spacy_nlp\"] = None\n",
        "\n",
        "# ---------- AUTH ----------\n",
        "def signup(email, password):\n",
        "    c.execute(\"SELECT * FROM users WHERE email=?\", (email,))\n",
        "    if c.fetchone(): return False\n",
        "    hashed = bcrypt.hashpw(password.encode(), bcrypt.gensalt())\n",
        "    c.execute(\"INSERT INTO users (email, password) VALUES (?,?)\", (email, hashed))\n",
        "    conn.commit(); return True\n",
        "\n",
        "def login(email, password):\n",
        "    c.execute(\"SELECT password FROM users WHERE email=?\", (email,))\n",
        "    row = c.fetchone()\n",
        "    return bool(row and bcrypt.checkpw(password.encode(), row[0]))\n",
        "\n",
        "def send_otp(email):\n",
        "    otp = random.randint(100000,999999)\n",
        "    st.session_state[\"otp_storage\"][email] = otp\n",
        "    st.info(f\"(Demo OTP) sent to {email}: {otp}\")\n",
        "\n",
        "def verify_otp(email, entered):\n",
        "    try:\n",
        "        return st.session_state[\"otp_storage\"].get(email) == int(entered)\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "# ---------- HISTORY DB ----------\n",
        "def save_history(email, essay, score, feedback, g, co, pl):\n",
        "    c.execute(\"INSERT INTO history (email, essay, score, feedback, grammar_score, coherence_score, plagiarism_score, date) VALUES (?,?,?,?,?,?,?,?)\",\n",
        "              (email, essay, score, feedback, g, co, pl, datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")))\n",
        "    conn.commit()\n",
        "\n",
        "def get_history(email):\n",
        "    c.execute(\"SELECT essay, score, feedback, grammar_score, coherence_score, plagiarism_score, date FROM history WHERE email=? ORDER BY date DESC\", (email,))\n",
        "    return c.fetchall()\n",
        "\n",
        "# ---------- METRICS ----------\n",
        "def grammar_score(essay):\n",
        "    # TextBlob-based simple heuristic (corrections count)\n",
        "    tb = TextBlob(essay)\n",
        "    corrections = 0\n",
        "    for s in tb.sentences:\n",
        "        corrected = str(s.correct())\n",
        "        if corrected.strip().lower() != str(s).strip().lower():\n",
        "            corrections += 1\n",
        "    score = max(0, 10 - corrections)\n",
        "    return round(min(score, 10),2)\n",
        "\n",
        "def coherence_score(essay):\n",
        "    nlp = st.session_state.get(\"spacy_nlp\")\n",
        "    if nlp:\n",
        "        sents = [s.text.strip() for s in nlp(essay).sents if len(s.text.strip())>10]\n",
        "    else:\n",
        "        sents = [s.strip() for s in essay.split('.') if len(s.strip())>10]\n",
        "    if len(sents) < 2:\n",
        "        return 5.0\n",
        "    try:\n",
        "        vec = TfidfVectorizer().fit_transform(sents)\n",
        "        sims = cosine_similarity(vec)\n",
        "        n = sims.shape[0]\n",
        "        sim_score = (sims.sum() - sims.trace())/(n*(n-1)) if n>1 else 0.0\n",
        "    except:\n",
        "        sim_score = 0.2\n",
        "    # transition words\n",
        "    transitions = [\"however\",\"moreover\",\"therefore\",\"furthermore\",\"consequently\",\"nevertheless\",\"in addition\"]\n",
        "    tcount = sum(essay.lower().count(t) for t in transitions)\n",
        "    s_trans = min(tcount/3,1.0)\n",
        "    s_sim = min(sim_score*2.0,1.0)\n",
        "    score = round((s_trans*0.4 + s_sim*0.6)*10,2)\n",
        "    return score\n",
        "\n",
        "def plagiarism_score(essay, email):\n",
        "    past = get_history(email)\n",
        "    if not past:\n",
        "        return 0.0\n",
        "    past_texts = [p[0] for p in past]\n",
        "    try:\n",
        "        vec = TfidfVectorizer().fit_transform(past_texts + [essay])\n",
        "        sims = cosine_similarity(vec[-1], vec[:-1]).flatten()\n",
        "        max_sim = float(sims.max()) if len(sims)>0 else 0.0\n",
        "    except:\n",
        "        max_sim = 0.0\n",
        "    return round(max_sim*100,2)\n",
        "\n",
        "def overall_score(essay,email):\n",
        "    g = grammar_score(essay)\n",
        "    co = coherence_score(essay)\n",
        "    pl = plagiarism_score(essay,email)\n",
        "    length_factor = min(len(essay)/800,1.0)*10\n",
        "    base = (g*0.30 + co*0.30 + length_factor*0.20)\n",
        "    penalty = (pl/100)*10*0.20\n",
        "    score = max(0.0, round(base - penalty,2))\n",
        "    return score, g, co, pl\n",
        "\n",
        "# ---------- AI FEEDBACK & REWRITER ----------\n",
        "@st.cache_resource\n",
        "def load_feedback_model():\n",
        "    return pipeline(\"text2text-generation\", model=FEEDBACK_MODEL, device=DEVICE)\n",
        "\n",
        "def generate_feedback(essay):\n",
        "    model = st.session_state.get(\"feedback_model\") or load_feedback_model()\n",
        "    st.session_state[\"feedback_model\"] = model\n",
        "    prompt = (\"You are an expert academic writing tutor. Provide 4 concise, actionable bullets to improve the essay: \"\n",
        "              \"1) Structure, 2) Grammar/style, 3) Vocabulary, 4) Concrete next steps. Keep bullets short.\\\\n\\\\nEssay:\\\\n\" + essay[:1600])\n",
        "    out = model(prompt, max_length=200, do_sample=False)\n",
        "    text = out[0].get(\"generated_text\", out[0].get(\"text\",\"\")).strip()\n",
        "    if text.startswith(prompt): text = text[len(prompt):].strip()\n",
        "    return text\n",
        "\n",
        "@st.cache_resource\n",
        "def load_rewriter():\n",
        "    return pipeline(\"text2text-generation\", model=FEEDBACK_MODEL, device=DEVICE)\n",
        "\n",
        "def rewrite_professional(essay):\n",
        "    rewriter = st.session_state.get(\"rewriter\") or load_rewriter()\n",
        "    st.session_state[\"rewriter\"] = rewriter\n",
        "    prompt = \"Rewrite the following essay to be more professional, concise, and academic while preserving meaning:\\\\n\\\\n\" + essay[:1600]\n",
        "    out = rewriter(prompt, max_length=600, do_sample=False)\n",
        "    text = out[0].get(\"generated_text\", out[0].get(\"text\",\"\")).strip()\n",
        "    if text.startswith(prompt): text = text[len(prompt):].strip()\n",
        "    return text\n",
        "\n",
        "# ---------- Grammar correction highlight ----------\n",
        "def corrected_text(essay):\n",
        "    tb = TextBlob(essay)\n",
        "    corrected = str(tb.correct())\n",
        "    return corrected\n",
        "\n",
        "def highlight_differences(original, corrected):\n",
        "    # token-level simple highlight: wrap corrected tokens that differ\n",
        "    orig_tokens = original.split()\n",
        "    corr_tokens = corrected.split()\n",
        "    seqm = difflib.SequenceMatcher(a=orig_tokens, b=corr_tokens)\n",
        "    out = []\n",
        "    for op, a0, a1, b0, b1 in seqm.get_opcodes():\n",
        "        if op == \"equal\":\n",
        "            out.extend(orig_tokens[a0:a1])\n",
        "        elif op in (\"replace\", \"insert\"):\n",
        "            # show corrected tokens wrapped\n",
        "            out.append(\"<mark>\" + \" \".join(corr_tokens[b0:b1]) + \"</mark>\")\n",
        "        elif op == \"delete\":\n",
        "            # show deletion as strike\n",
        "            out.append(\"<del>\" + \" \".join(orig_tokens[a0:a1]) + \"</del>\")\n",
        "    return \" \".join(out)\n",
        "\n",
        "# ---------- PDF report ----------\n",
        "def make_pdf(email, essay, score, feedback, g, co, pl, rewritten=None):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "    pdf.cell(0,10, \"NLP Essay Grader Report\", ln=True, align=\"C\")\n",
        "    pdf.ln(4)\n",
        "    pdf.cell(0,8, f\"User: {email}\", ln=True)\n",
        "    pdf.cell(0,8, f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\", ln=True)\n",
        "    pdf.cell(0,8, f\"Overall Score: {score}/10\", ln=True)\n",
        "    pdf.cell(0,8, f\"Grammar: {g}/10  |  Coherence: {co}/10  |  Plagiarism: {pl}%\", ln=True)\n",
        "    pdf.ln(6)\n",
        "    pdf.multi_cell(0,6,\"Feedback:\\\\n\" + feedback)\n",
        "    if rewritten:\n",
        "        pdf.ln(4)\n",
        "        pdf.multi_cell(0,6,\"Rewritten (professional):\\\\n\" + rewritten[:4000])\n",
        "    else:\n",
        "        pdf.ln(4)\n",
        "        pdf.multi_cell(0,6,\"Essay:\\\\n\" + essay[:4000])\n",
        "    out = f\"report_{int(time.time())}.pdf\"\n",
        "    pdf.output(out)\n",
        "    return out\n",
        "\n",
        "# ---------- STREAMLIT UI ----------\n",
        "st.set_page_config(page_title=\"Professional AI Essay Grader\", layout=\"wide\")\n",
        "st.markdown(\\\"\\\"\\\"<style>\n",
        "body { background: linear-gradient(180deg,#f7f9fb,#eef2f7); }\n",
        ".card { background:white; border-radius:12px; padding:16px; box-shadow:0 6px 18px rgba(0,0,0,0.06); }\n",
        ".stButton>button { background-color:#0b63ce; color:white; border-radius:8px; height:42px; }\n",
        "div[data-testid='stSidebar'] { background-color:#f2f4f8; }\n",
        "mark { background-color: #fffb91; }\n",
        "del { color:#b0b0b0; text-decoration: line-through; }\n",
        "</style>\\\"\\\"\\\", unsafe_allow_html=True)\n",
        "\n",
        "# Header\n",
        "col1, col2 = st.columns([3,1])\n",
        "with col1:\n",
        "    st.title(\"NLP Essay Grader â€” Professional Dashboard\")\n",
        "    st.caption(\"AI feedback, grammar corrections, rewriter, coherence & plagiarism checks, downloadable reports.\")\n",
        "with col2:\n",
        "    st.image(\"https://cdn-icons-png.flaticon.com/512/2917/2917242.png\", width=64)\n",
        "\n",
        "# Auth\n",
        "if not st.session_state[\"logged_in\"]:\n",
        "    left, right = st.columns(2)\n",
        "    with left:\n",
        "        st.subheader(\"Login\")\n",
        "        email = st.text_input(\"Email\", key=\"login_e\")\n",
        "        password = st.text_input(\"Password\", type=\"password\", key=\"login_p\")\n",
        "        if st.button(\"Login\", key=\"btn_login\"):\n",
        "            if login(email, password):\n",
        "                st.session_state[\"logged_in\"] = True\n",
        "                st.session_state[\"user_email\"] = email\n",
        "                st.success(\"Logged in\")\n",
        "                st.experimental_rerun()\n",
        "            else:\n",
        "                st.error(\"Invalid credentials\")\n",
        "    with right:\n",
        "        st.subheader(\"Sign Up\")\n",
        "        new_email = st.text_input(\"New Email\", key=\"signup_e\")\n",
        "        new_password = st.text_input(\"New Password\", type=\"password\", key=\"signup_p\")\n",
        "        if st.button(\"Send OTP\", key=\"btn_otp\"):\n",
        "            if new_email and new_password:\n",
        "                send_otp(new_email)\n",
        "            else:\n",
        "                st.warning(\"Enter email & password\")\n",
        "        otp_in = st.text_input(\"Enter OTP\", key=\"otp_in\")\n",
        "        if st.button(\"Verify & Create Account\", key=\"btn_create\"):\n",
        "            if verify_otp(new_email, otp_in):\n",
        "                if signup(new_email, new_password):\n",
        "                    st.success(\"Account created â€” please log in\")\n",
        "                    st.session_state[\"otp_storage\"].pop(new_email, None)\n",
        "                else:\n",
        "                    st.warning(\"Email exists\")\n",
        "            else:\n",
        "                st.error(\"Invalid OTP\")\n",
        "else:\n",
        "    st.sidebar.success(f\"Signed in as {st.session_state['user_email']}\")\n",
        "    if st.sidebar.button(\"Logout\"):\n",
        "        st.session_state[\"logged_in\"] = False\n",
        "        st.session_state[\"user_email\"] = None\n",
        "        st.experimental_rerun()\n",
        "\n",
        "    page = st.sidebar.radio(\"Navigate\", [\"Grader\", \"History\", \"Account\", \"Rewrite & Correct\"])\n",
        "\n",
        "    if page == \"Grader\":\n",
        "        st.subheader(\"Write or paste your essay\")\n",
        "        essay = st.text_area(\"Essay\", height=300)\n",
        "        if st.button(\"Evaluate\"):\n",
        "            if not essay.strip():\n",
        "                st.warning(\"Please enter text\")\n",
        "            else:\n",
        "                with st.spinner(\"Computing feedback and metrics...\"):\n",
        "                    feedback = generate_feedback(essay)\n",
        "                    score, g, co, pl = overall_score(essay, st.session_state[\"user_email\"])\n",
        "                    save_history(st.session_state[\"user_email\"], essay, score, feedback, g, co, pl)\n",
        "                    corrected = corrected_text(essay)\n",
        "                    highlighted = highlight_differences(essay, corrected)\n",
        "                st.success(f\"Overall score: {score}/10\")\n",
        "                st.markdown(\\\"\\\"\\\"<div class='card'><h4>AI Feedback</h4><div>\\\"\\\"\\\" + feedback.replace('\\\\n','<br>') + \\\"\\\"\\\"</div></div>\\\"\\\"\\\", unsafe_allow_html=True)\n",
        "                st.markdown(\"### Grammar correction (suggested)\")\n",
        "                st.markdown(highlighted, unsafe_allow_html=True)\n",
        "                st.markdown(\"### Metrics\")\n",
        "                c1,c2,c3 = st.columns(3)\n",
        "                c1.metric(\"Grammar\", f\\\"{g}/10\\\")\n",
        "                c2.metric(\"Coherence\", f\\\"{co}/10\\\")\n",
        "                c3.metric(\"Plagiarism\", f\\\"{pl}%\\\")\n",
        "                # PDF\n",
        "                pdf_path = make_pdf(st.session_state[\"user_email\"], essay, score, feedback, g, co, pl, rewritten=None)\n",
        "                with open(pdf_path,\"rb\") as f:\n",
        "                    st.download_button(\"Download Report (PDF)\", f, file_name=pdf_path)\n",
        "                st.balloons()\n",
        "\n",
        "    elif page == \"Rewrite & Correct\":\n",
        "        st.subheader(\"Rewrite to Professional & Grammar Correction\")\n",
        "        essay2 = st.text_area(\"Paste essay to rewrite or correct\", height=300)\n",
        "        colA, colB = st.columns(2)\n",
        "        with colA:\n",
        "            if st.button(\"Show Grammar Correction\"):\n",
        "                if not essay2.strip():\n",
        "                    st.warning(\"Enter essay\")\n",
        "                else:\n",
        "                    corr = corrected_text(essay2)\n",
        "                    highlighted = highlight_differences(essay2, corr)\n",
        "                    st.markdown(\"### Corrected (highlighted differences):\")\n",
        "                    st.markdown(highlighted, unsafe_allow_html=True)\n",
        "        with colB:\n",
        "            if st.button(\"Rewrite Professionally\"):\n",
        "                if not essay2.strip():\n",
        "                    st.warning(\"Enter essay\")\n",
        "                else:\n",
        "                    with st.spinner(\"Generating professional rewrite...\"):\n",
        "                        rewritten = rewrite_professional(essay2)\n",
        "                    st.markdown(\"### Professional Rewrite\")\n",
        "                    st.write(rewritten)\n",
        "                    # allow download\n",
        "                    temp_pdf = make_pdf(st.session_state[\"user_email\"] or \"guest\", essay2, 0, rewritten, 0,0,0, rewritten=rewritten)\n",
        "                    with open(temp_pdf,\"rb\") as f:\n",
        "                        st.download_button(\"Download Rewritten (PDF)\", f, file_name=temp_pdf)\n",
        "\n",
        "    elif page == \"History\":\n",
        "        st.subheader(\"Your History\")\n",
        "        history = get_history(st.session_state[\"user_email\"])\n",
        "        if not history:\n",
        "            st.info(\"No history\")\n",
        "        else:\n",
        "            scores = [h[1] for h in history][::-1]\n",
        "            dates = [h[6] for h in history][::-1]\n",
        "            fig, ax = plt.subplots(figsize=(8,3))\n",
        "            ax.plot(dates, scores, marker='o')\n",
        "            ax.set_xlabel(\"Date\"); ax.set_ylabel(\"Score\")\n",
        "            plt.xticks(rotation=25)\n",
        "            st.pyplot(fig)\n",
        "            for h in history:\n",
        "                st.markdown(f\\\"**Date:** {h[6]}  |  **Score:** {h[1]}/10  |  **Plagiarism:** {h[5]}%\\\")\n",
        "                st.info(h[2])\n",
        "                st.write(h[0][:400] + (\"...\" if len(h[0])>400 else \"\"))\n",
        "\n",
        "    else:\n",
        "        st.subheader(\"Account\")\n",
        "        st.write(f\\\"Email: **{st.session_state['user_email']}**\\\")\n",
        "        st.write(\\\"This app includes: AI feedback, grammar highlight, professional rewriter, downloadable reports.\\\")\n",
        "\"\"\"\n",
        "\n",
        "with open(\"app.py\",\"w\") as f:\n",
        "    f.write(app_code)\n",
        "\n",
        "print(\"âœ… app.py written.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUzV60j9G-Fi",
        "outputId": "946e1005-ff29-4ac3-eb5f-29694cbeff4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… app.py written.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3 â€” run app and expose via ngrok\n",
        "from pyngrok import ngrok\n",
        "import time, os\n",
        "\n",
        "# kill old\n",
        "!pkill -f ngrok || true\n",
        "!pkill -f streamlit || true\n",
        "time.sleep(1)\n",
        "\n",
        "# run streamlit in background\n",
        "get_ipython().system_raw('streamlit run app.py --server.port 8501 &')\n",
        "\n",
        "time.sleep(5)\n",
        "\n",
        "# disconnect previous tunnels (best effort)\n",
        "try:\n",
        "    for t in ngrok.get_tunnels():\n",
        "        try:\n",
        "            ngrok.disconnect(t.public_url)\n",
        "        except:\n",
        "            pass\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    tunnel = ngrok.connect(addr=8501, proto=\"http\")\n",
        "    print(\"ðŸš€ App URL:\", tunnel.public_url)\n",
        "except Exception as e:\n",
        "    print(\"Could not start ngrok tunnel:\", e)\n",
        "    print(\"If you see a tunnel-limit error, restart the Colab runtime (Runtime -> Restart runtime) and re-run the three cells.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zK1oPfQyI5aN",
        "outputId": "6f148e88-b005-4459-fda4-265cf362cc9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "^C\n",
            "ðŸš€ App URL: https://c39e05577dc2.ngrok-free.app\n"
          ]
        }
      ]
    }
  ]
}